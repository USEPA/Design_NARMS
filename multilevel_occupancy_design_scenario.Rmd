---
title: "eDNA study design simulations"
author: "Roy Martin"
date: "`r format( Sys.time(), '%B %d, %Y' )`"
output:
  github_document:
    number_sections: TRUE
    df_print: "tibble"
    math_method: 
      engine: webtex
    #  url: https://latex.codecogs.com/svg.image?
    html_preview: TRUE
    keep_html: TRUE
bibliography: references.bib
link-citations: yes
---

This document describes and provides code for a probabilistic ("prior predictive") simulation of eDNA detection data for a hypothetical target organism across a user-defined distribution of sites, samples within sites, and replicate qPCR observations of those samples. In addition, sites were distributed among two land use types, which was parameterized to have an effect on occupancy rates.

```{r setup, warning=FALSE, message=FALSE}
# Lets now set up our R environment to run the simulation.
library(ggplot2)
library(ggExtra)
library(gridExtra)
library(RColorBrewer)
library(truncnorm)
library(stringr)
library(tidyverse)
library(rstan)
library(loo)
library(bayesplot)
library(tidybayes)

options(mc.cores = 4)
rstan_options(auto_write = TRUE)
options(loo.cores = 4)

options(max.print = 9999)
```

# Model description
The model is a three-level occupancy model based on @Nichols_etal_2008 and @Schmidt_etal_2013. The basic model below consists of a sequence of three coupled Bernoulli trials for describing the array of nested data, $y_{i,j,k}$, where we have an observed detection ($y_{ijk} = 1$) or not ($y_{ijk} = 0$) for each PCR replicate $k$, nested in a water sample $j$, nested in a sample visit day $t$ at a site $i$. If we plan to completely cross site and day, we would have $S \times T = 30 \times 17 = 510$ total sampling occasions.

$$\textbf{Level-3: latent state of occupancy}$$
$z$ = latent state (0 or 1) of occupancy
$\psi$ = probability of occupancy
$$z_{i} \sim Bernoulli(\psi_i)$$

$$\textbf{Level-2: availability parameter}$$
$a$ = latent state (0 or 1) of availability (in water sample) for detection via qPCR
$\theta$ = probability of capturing DNA in water sample and it being available for observation, conditional on occupancy.
$$a_{ij} | z_i \sim Bernoulli( z_i\theta_{ij} )$$

$$\textbf{Level-1: observations}$$
$y$ = observed detection (0 or 1) via qPCR
$p$ = probability of detecting via qPCR, conditional on it being available in water sample. 
$$y_{ijk} | a_{ij} \sim Bernoulli( a_{ij} p_{ijk} )$$
# Prior predictive simulation

## Dimensions
Set the dimensions of the hypothetical data based on the number of sites, water samples, and qPCR replicates.
```{r simulation_multilevel_occ, echo=TRUE}
nag <- 15 # number of ag sites in study
nurban <- 15 # number of urban sites in study
nsite <- nag + nurban # number of sites in study
nsamp <- 5 # number of replicate water samples per site
nrep <- 4 # number of replicate qPCR samples per water sample (per site and date)
nsim <- 1e3 # number of simulated draws from joint prior predictive distribution
```

The number of sites is `r nsite`. The total number of water samples is `r nsite * nsamp`. The total number of qPCR runs is `r nsite * nsamp * nrep`.

Next create containers at each level of the model to hold the simulated values.
```{r containers_multilevel_occupancy, include=FALSE}
# make an array placeholder for siumation, s, of the latent occupancy state, z, for each site, i
z_i <- array(NA, dim = c(nsite, nsim))

# make an array placeholder for latent availability state, a, for water rep, j, in site i
a_ij <- array(NA, dim = c(nsite, nsamp, nsim))

# make an array placeholder for simulation, s, of oserved detections, y, for each pcr rep, k, in water sample, j, and site i
y_ijk <- array(NA, dim = c(nsite, nsamp, nrep, nsim))

# make an array placeholder for simulation, s, of the paramter psi or P( site occupied )
psi_i <- array(NA, dim = c(nsite, nsim))

# make an array placeholder for simulation, s, of the parameter theta or P( available in water sample | site occupied )
theta_ij <- array(NA, dim = c(nsite, nsamp, nsim))

# make an array placeholder for simulation, s, of the paramter p or P( detect in PCR rep | available in water sample )
p_ijk <- array(NA, dim = c(nsite, nsamp, nrep, nsim))

```


## Priors
Set priors for the parameters to be estimated from data.

### $\psi$
The linear predictor for the occupancy parameter includes an intercept term, a land use effect, and a random site effect:
$$z_{i} \sim Bernoulli(\psi_i)$$
$$logit( \psi_i ) = \alpha_\psi + \beta*X_i + \gamma_{\psi_i}$$

#### Intercept
```{r prior_psi_logodds, fig.align='center', fig.width=6, fig.height=4}
# prior for log-odds-scale intercept parameter for psi
loc_a_psi = 0
scale_a_psi = 0.5
a_psi <- rnorm(nsim, loc_a_psi, scale_a_psi)
```

The intercept in this model can be interpreted as the baseline probability of occupancy for a hypothetical "ag" site. It is centered over 0.5 and varies around that baseline by according to the scale parameter representing _a priori_ uncertainty in that parameter.
```{r prior_psi_prob, echo=FALSE, fig.align='center', fig.height=4, fig.width=4}
# plot it
ggplot(tibble(x = plogis(seq(- 10, 10, 0.01)), y = dnorm(seq(- 10, 10, 0.01), loc_a_psi, scale_a_psi)), 
        aes(x = x, y = y)) + 
  geom_line() + 
  ylab("density") + xlab(expression(paste(logit^-1,  (alpha[psi]))))
```

#### Land use effect
```{r prior_psi_effect_logodds, fig.align='center', fig.width=6, fig.height=4}
# prior for log-odds-scale intercept parameter for psi
loc_beta_psi = 1
scale_beta_psi = 0.2
beta_psi <- rnorm(nsim, loc_beta_psi, scale_beta_psi)
```

The land use effect is centered over 1 on the logit scale, but in the context of the baseline (intercept above) and on the probability scale, it shifts the baseline probability centered over 0.5 for "ag" sites to a probability closer to 0.75 for "urban" sites.
```{r prior_psi_effect_prob, echo=FALSE, fig.align='center', fig.height=4, fig.width=4}
# plot it
ggplot(tibble(x = plogis(seq(- 10, 10, 0.01)), 
              y = dnorm(seq(- 10, 10, 0.01), loc_beta_psi, scale_beta_psi)), 
        aes(x = x, y = y)) + 
  geom_line() + 
  ylab("density") + xlab(expression(paste(logit ^ -1, (Beta[psi]))))
```

#### $\sigma_{\psi}$
```{r prior_sigma_gamma_psi}
# prior for scale parameter of varying site effects
loc_sigma_gamma_psi = 0
scale_sigma_gamma_psi = 0.3
sigma_gamma_psi <- rtruncnorm(nsim, a = 0, mean = loc_sigma_gamma_psi, sd = scale_sigma_gamma_psi)
```

The sigma parameter here defines scale of ("random") site-to-site effects on $\psi$ not captured by the "fixed" intercept and land use effects. Effectively, $\gamma_{\psi}$ defines unmeasured process variation between sites and $\sigma_{\psi}$ defines the scale of that variation.

```{r prior_sigma_gamma_psi_plot, echo=FALSE, fig.align='center', fig.height=4, fig.width=4}
# plot it
ggplot(tibble(x = seq(0, 2, 0.01), 
              y = dtruncnorm(seq(0, 2, 0.01), 
                             a = 0, 
                             mean = loc_sigma_gamma_psi, 
                             sd = scale_sigma_gamma_psi)), 
        aes(x = x, y = y)) + 
  geom_line() + 
  ylab("density") + xlab(expression(sigma[gamma[psi]]))
```

### $\theta$
$$a_{ij} | z_i \sim Bernoulli( z_i\theta_{ij} )$$
$$logit( \theta_{ij} ) = \alpha_\theta + \gamma_{\theta_i}$$

#### Intercept
```{r prior_theta_logodds, fig.align='center', fig.width=6, fig.height=4}
# prior for log-odds-scale intercept parameter for psi
loc_a_theta = 1.5
scale_a_theta = 0.25
a_theta <- rnorm(nsim, loc_a_theta, scale_a_theta)
```

The probability of obtaining the target eDNA, conditional on it being in the site, was centered over about 0.8.
```{r prior_theta_prob, echo=FALSE, fig.align='center', fig.height=4, fig.width=4}
# plot it
ggplot(tibble(x = plogis(seq(- 10, 10, 0.01)), y = dnorm(seq(- 10, 10, 0.01), loc_a_theta, scale_a_theta)), 
        aes(x = x, y = y)) + 
  geom_line() + 
  ylab("density") + xlab(expression(paste(logit ^ -1, (alpha[theta])))) +
  scale_x_continuous(limits = c(0, 1))
```

#### $\sigma_{\theta}$
```{r prior_sigma_gamma_theta}
# prior for scale parameter of varying site effects
loc_sigma_gamma_theta = 0
scale_sigma_gamma_theta = 0.1
sigma_gamma_theta <- rtruncnorm(nsim, a = 0, mean = loc_sigma_gamma_theta, sd = scale_sigma_gamma_theta)
```

Again, $\sigma_{\theta}$ defines the scale of unmeasured process variation around the fixed intercept.
```{r prior_sigma_gamma_theta_plot, echo=FALSE, fig.align='center', fig.height=4, fig.width=4}
# plot it
ggplot(tibble(x = seq(0, 1, 0.01), 
              y = dtruncnorm(seq(0, 1, 0.01), 
                             a = 0, 
                             mean = loc_sigma_gamma_theta, 
                             sd = scale_sigma_gamma_theta)), 
        aes(x = x, y = y)) + 
  geom_line() + 
  ylab("density") + xlab(expression(sigma[gamma[theta]]))
```

### p

$$logit( p_{ijk} ) = \alpha_p + \gamma_{p_i}$$

#### Intercept
```{r prior_p_logodds, fig.align='center', fig.width=6, fig.height=4}
# prior for log-odds-scale intercept parameter for p
loc_a_p = 1.25
scale_a_p = 0.25
a_p <- rnorm(nsim, loc_a_p, scale_a_p)
```

The probability of detecting eDNA conditional on it being available in the water sample is also centered over about 0.8.
```{r prior_p_prob, echo=FALSE, fig.align='center', fig.height=4, fig.width=6}
# plot it
ggplot(tibble(x = plogis(seq(- 10, 10, 0.01)), y = dnorm(seq(- 10, 10, 0.01), loc_a_p, scale_a_p)), 
        aes( x = x, y = y ) ) + 
  geom_line() + 
  ylab("density") + xlab(expression(paste(logit ^ -1, (alpha[p])))) +
  scale_x_continuous(limits = c(0, 1))
```

#### Sigma site
```{r prior_sigma_gamma_p}
# prior for scale parameter of varying site effects
loc_sigma_gamma_p = 0
scale_sigma_gamma_p = 0.05
sigma_gamma_p <- rtruncnorm(nsim, a = 0, mean = loc_sigma_gamma_p, sd = scale_sigma_gamma_p)
```

The scale of unmeasured process variation in $p$ is set pretty low.
```{r prior_sigma_gamma_p_plot, echo=FALSE, fig.align='center', fig.height=4, fig.width=4}
# plot it
ggplot(tibble(x = seq(0, 1, 0.01), 
              y = dtruncnorm(seq(0, 1, 0.01), 
                             a = 0, 
                             mean = loc_sigma_gamma_p, 
                             sd = scale_sigma_gamma_p)), 
        aes(x = x, y = y)) + 
  geom_line() + 
  ylab("density") + xlab(expression(sigma[gamma[p]]))
```

## Simulate data
Simulate draws from the prior predictive distribution based on our model and priors defined above.
```{r sim_multilevel_occupancy, eval=TRUE, include=TRUE}
# Dummy variable for land use
X_land <- c(rep(0, nag), rep(1, nurban))
# Simulate varying effects
gamma_psi <- array(NA, dim = c(nsite, nsim))
gamma_theta <- array(NA, dim = c(nsite, nsim))
gamma_p <- array(NA, dim = c(nsite, nsim))

for (i in 1:nsite){
  gamma_psi[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_psi)
  gamma_theta[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_theta)
  gamma_p[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_p)
}

# Run the prior predictive simulation through likelihood
for(i in 1:nsite){
    psi_i[i, ] <- plogis(a_psi + beta_psi * X_land[i] + gamma_psi[i, ]) # back-transform
    z_i[i, ] <- rbinom(nsim, 1, psi_i[i, ])
  
  for (j in 1:nsamp) {
    theta_ij[i, j, ] <- plogis( a_theta + gamma_theta[i, ]) 
    a_ij[i, j, ] <- rbinom(nsim, 1, z_i[i, ] * theta_ij[i, j, ])
   
    for (k in 1:nrep) {
      p_ijk[i, j, k, ] <- plogis(a_p + gamma_p[i, ])
      y_ijk[i, j, k, ] <- rbinom(nsim, 1, a_ij[ i, j, ] * p_ijk[ i, j, k, ])
      }
    }
  }
```

### Occupancy: Ag sites
using the prior predictive simulation above, we can summarize some of the implications of our beliefs in terms of practical conditions in this hypothetical system. For example, give our chosen model and our priors beliefs about its parameters and our uncertainty in their true values, the simulation indicats that we believe that anywhere between 1 and 15 of the 15 "Ag" sites are occupied, with the most likely value being about 8.
```{r distribution_occupancy_ag_sites, echo=FALSE, fig.align='center', fig.height=4, fig.width=4}
qplot(apply(z_i[X_land==0,], 2, sum), binwidth = 1) + 
      scale_x_continuous(breaks = c(0, 5, 10, 15), minor_breaks = seq(0, 17, 1)) +
      theme(axis.title.x = element_text(size = 10)) +
      theme(axis.title.y = element_text()) +
      theme(axis.title.y = element_blank()) +
  ylab(paste0("Number of simulations (", nsim, "\ possible)")) +
  xlab(paste0("Number of occupied Ag sites (", nag, "\ ", "possible)"))
```

### Occupancy: Urban sites
Our simulation also indicates that we believe anywhere between 1 and 15 "urban" sites are occupied, with the most likely value being 11 and most of probability is for a larger number of occupied sites relative to the "ag" sites.
```{r distribution_occupancy_urban_sites, echo=FALSE, fig.align='center', fig.height=4, fig.width=4}
qplot(apply(z_i[X_land==1,], 2, sum), binwidth = 1) + 
      scale_x_continuous(breaks = c(0, 5, 10, 15), minor_breaks = seq(0, 17, 1)) +
      theme(axis.title.x = element_text(size = 10)) +
      theme(axis.title.y = element_text()) +
      theme(axis.title.y = element_blank()) +
  ylab(paste0("Number of simulations (", nsim, "\ possible)")) +
  xlab(paste0("Number of occupied urban sites (", nurban, "\ ", "possible)"))
```

### Frequency of detections
We can look at similar implications for the probability of detections at the qPCR scale, etc.
```{r distribution_pcr_detects, echo=FALSE}
qplot(x = apply(y_ijk, 4, sum) / (nsite * nsamp * nrep), binwidth = 0.01) + 
  expand_limits(x = c(0, 1)) +
  xlab(paste0("Proportion of\ " , nsite * nsamp * nrep, "\ total PCR samples as positive detections")) +
  ylab(paste0("Number of simulations (", nsim, "\ possible)"))
```

### Replicate datasets
We can also use the simulation to look at the hypothetical world of potential datasets that could be collected given our model and priors. Below we show 20 such possible datasets. And the exact parameters for $\psi$, $\theta$, and $p$ that they were generated from. Note that even for those fixed parameter values, the dataset drawn could still look different than what was drawn here.
```{r frequency_yrep, echo=FALSE}
n_yrep <- 20 # number of replicate datasest to draw
sim_draw <- sample(1:nsim, n_yrep, replace = F) # assign random draw

psi_rep <- psi_i[, sim_draw] # psi for datasets drawn
theta_rep <- theta_ij[, , sim_draw] # theta for datasets drawn
p_rep <- p_ijk[, , , sim_draw] # p for datasets drawn
y_rep <- y_ijk[, , , sim_draw] # "oberved" y for each of the n_yrep datasets

# create empty list of dataframes to store y_rep data in frequency of pcr detects format
y_rep_freq <- vector('list', n_yrep)

# draw sample of datasets and re-format for plot
for(i in 1:n_yrep){
 y_rep_freq[[i]] <- data.frame(t(apply(y_rep[, , , i], 1, rowSums))) %>%
  gather(variable, value) %>%
  mutate(samples = rep(seq(1, nsamp, 1), nsite)) %>%
  rename(day = variable, 
          pcr_detects = value,
          water_rep = samples) %>%
  mutate(day = rep(seq(1, nsite, 1), each = nsamp))
}

# build a plot function and color palette
myfill <- colorRampPalette(rev(brewer.pal(nrep, "Spectral")))


plot_yrep <- function(data, rep){
  ggplot(data[[rep]], aes(x = water_rep, y = day, size = pcr_detects, color = pcr_detects)) + 
    theme_bw() +
    geom_point(alpha = 0.6) + 
    scale_size_identity("PCR detects") + 
    scale_fill_gradientn(colours = myfill) +
    scale_x_discrete("Water sample", limits = factor(seq(1, nsamp, 1))) + 
    scale_y_discrete("Site", limits = factor(seq(1, nsite, 1))) + 
    theme(axis.title.x = element_text(size=10, vjust=1),
           axis.title.y = element_text(size=10, vjust=1),
           axis.text.y = element_text(size=8, angle=360), 
           axis.text.x = element_text(angle=360, size=8, vjust=0.2),
           legend.position = "none",
           plot.title = element_text(size = 8, face = "bold")
           ) +
    ggtitle(bquote(list(psi == .(round(psi_rep[ 1, rep ], 2)),
                           theta == .(round( theta_rep[ 1, 1, rep ], 2)),
                           p == .(round(p_rep[ 1, 1, 1, rep ], 2)))))
 }

# make up dataset with all combinations for legend
y_rep_legend <- data.frame(day = rep(seq(1, nsite, 1), each = nsamp),
                            water_rep = rep(seq(1, nsamp, 1), nsite),
                            pcr_detects = sample(seq(0, nrep, 1), nsamp * nsite , replace = T))

# make fake plot with legend to extract
p_legend <- ggplot(y_rep_legend, aes(x = water_rep, y = day, size = pcr_detects, color = pcr_detects)) + 
  theme_bw() +
  geom_point(alpha = 0.6) + 
  scale_size_area(max_size = 4) + 
  scale_fill_gradientn(colours = myfill) +
  theme(legend.title = element_text( size=10),
        legend.text = element_text(size=10),
        legend.position = "top",
        legend.margin = margin(0, 0, 0, 0),
        legend.box.margin = margin(-10, 0, -10, -5)
        )

# fn to extract legend
get_legend <- function(myggplot){
  tmp <- ggplot_gtable(ggplot_build(myggplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
}

p_legend <- get_legend(p_legend)

plot_grid <- lapply(seq(1, n_yrep, 1), plot_yrep, data = y_rep_freq)

plot_out <- arrangeGrob( 
  p_legend,
  do.call(arrangeGrob, c(plot_grid, ncol = 5)),
  ncol = 1,
  nrow = 2,
  heights = c(0.04, 0.96))
```


```{r frequency_plot, echo=FALSE, fig.align='center', fig.height=20, fig.width=10}
plot(plot_out)
```


# Design scenarios

## 30 sites
In this first scenario, we take the same priors from above, but we fix the true land use effect to $\beta_{psi} = 1$. Then we manipulate the number of sites, samples, qPCR reps and see how well our Stan model recovers the true parameter estimate and its uncertainty. Below, we fix $\beta_{psi}$ to be exactly 1 with no uncertainty and re-simulate a new batch of hypothetical datasets. Then we randomly select a single simulated dataset and use a $\textbf{Stan}$ model (below) to estimate the parameters of the model conditional on the (hypothetical) data. To get a more rigorous summary of our design and how things like sample sizes and prior uncertainty affect our ability to detect the effect, we would want iterate this process thousands of times and then summarize things like: how many times did our parameter estimate for $\beta_{psi}$ include the true value (1)? How many times did our estimate have the right sign (positive vs. negative effect)? How many times or what proportion of our estimates did not include zero? etc.
```{r simulation_multilevel_occ_2, echo=TRUE}
nag <- 15 # number of ag sites in study
nurban <- 15 # number of urban sites in study
nsite <- nag + nurban # number of sites in study
nsamp <- 5 # number of replicate water samples per site
nrep <- 4 # number of replicate qPCR samples per water sample (per site and date)
nsim <- 1e3 # number of simulated draws from joint prior predictive distribution
```

```{r n_sites_2}
nsite
```

```{r n_water_samples_2}
nsite * nsamp
```
The total number of qPCR runs is equat to the number of sites, times the number of water samples, times the number of qPCR reps per water sample. This number is shown below and perhaps gives a more practical sense of the effort required to try to estimate this particular hypothetical effect.
```{r n_qpcr_runs_2}
nsite * nsamp * nrep
```

```{r containers_multilevel_occupancy_1, include=FALSE}
# make an array placeholder for siumation, s, of the latent occupancy state, z, for each site, i
z_i <- array(NA, dim = c(nsite, nsim))

# make an array placeholder for latent availability state, a, for water rep, j, in site i
a_ij <- array(NA, dim = c(nsite, nsamp, nsim))

# make an array placeholder for simulation, s, of oserved detections, y, for each pcr rep, k, in water sample, j, and site i
y_ijk <- array(NA, dim = c(nsite, nsamp, nrep, nsim))

# make an array placeholder for simulation, s, of the paramter psi or P( site occupied )
psi_i <- array(NA, dim = c(nsite, nsim))

# make an array placeholder for simulation, s, of the parameter theta or P( available in water sample | site occupied )
theta_ij <- array(NA, dim = c(nsite, nsamp, nsim))

# make an array placeholder for simulation, s, of the paramter p or P( detect in PCR rep | available in water sample )
p_ijk <- array(NA, dim = c(nsite, nsamp, nrep, nsim))

```

Fixed land use effect
```{r prior_psi_effect_logodds_2, fig.align='center', fig.width=6, fig.height=4}
# fixed slope effect of land use
beta_psi <- 1
```

### Simulate draws
```{r sim_multilevel_occupancy_2, eval=TRUE, include=TRUE}
# Dummy variable for land use
X_land <- c(rep(0, nag), rep(1, nurban))
# Simulate varying effects
gamma_psi <- array(NA, dim = c(nsite, nsim))
gamma_theta <- array(NA, dim = c(nsite, nsim))
gamma_p <- array(NA, dim = c(nsite, nsim))

for (i in 1:nsite){
  gamma_psi[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_psi)
  gamma_theta[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_theta)
  gamma_p[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_p)
}

# Run the prior predictive simulation through likelihood
for(i in 1:nsite){
    psi_i[i, ] <- plogis(a_psi + beta_psi * X_land[i] + gamma_psi[i, ]) # back-transform
    z_i[i, ] <- rbinom(nsim, 1, psi_i[i, ])
  
  for (j in 1:nsamp) {
    theta_ij[i, j, ] <- plogis( a_theta + gamma_theta[i, ]) 
    a_ij[i, j, ] <- rbinom( nsim, 1, z_i[i, ] * theta_ij[i, j, ])
   
    for (k in 1:nrep) {
      p_ijk[i, j, k, ] <- plogis( a_p + gamma_p[i, ])
      y_ijk[i, j, k, ] <- rbinom( nsim, 1, a_ij[ i, j, ] * p_ijk[ i, j, k, ] )
      }
    }
  }
```

### Pick a random dataset
Below we pick a single random dataset from the world of possible datasets given our assumptions outlined above. The code below picks the dataset and then we also print out the true parameter values used to generate this specific datset. After fitting the model with this dataset below, we can use these values to get a sense of how well the model recovered the parameters.
```{r sample_simulation_2}
sel <- sample(1:1000, 1, replace = FALSE)
fake_data <- y_ijk[, , , sel] # draw the fake dataset from 1000 simulations

data.frame(
  a_psi = a_psi[sel],
  beta_psi = beta_psi,
  sigma_gamma_psi = sigma_gamma_psi[[sel]],
  a_theta = a_theta[sel],
  sigma_gamma_theta = sigma_gamma_theta[[sel]],
  a_p = a_p[sel],
  sigma_gamma_p = sigma_gamma_p[[sel]]
) %>% t()
```

### A model in Stan
```{stan stan_mocc_model_2, output.var = 'mocc'}
data {
  int<lower = 1> nsite;
  int<lower = 1> nsamp;
  int<lower = 1> nrep;
  int<lower = 0, upper = 1> y[nsite, nsamp, nrep];
  int<lower = 0, upper =1> X_Land[nsite];
  int<lower=1> site[nsite];
  int<lower = 1> n_possible;
  matrix<lower = 0, upper = 1>[n_possible, nsamp] alpha_potential;
}

transformed data {
  int<lower = 0, upper = 1> known_present[nsite];
  int<lower = 0, upper = 1> known_available[nsite, nsamp];
  for (i in 1:nsite) {
    known_present[i] = 0;
    for (j in 1:nsamp) {
      known_available[i, j] = 0;
      for (k in 1:nrep) {
        if (y[i, j, k] == 1) {
         known_present[i] = 1;
         known_available[i, j] = 1;
        }
      }
    }
  }
}

parameters {
  real a_psi ;
  real a_theta;
  real a_p;
  real beta; // beta psi
  real<lower = 0> sigma_gamma_psi;
  real<lower = 0> sigma_gamma_theta;
  real<lower = 0> sigma_gamma_p;
  vector[nsite] z_psi;
  vector[nsite] z_theta;
  vector[nsite] z_p;
}

transformed parameters {
  vector[nsite] log_lik;
  real<lower = 0, upper = 1> psi[nsite];
  real<lower = 0, upper = 1> theta[nsite, nsamp];
  real<lower = 0, upper = 1> p[nsite, nsamp, nrep];
  vector[nsite] gamma_psi = z_psi * sigma_gamma_psi;
  vector[nsite] gamma_theta = z_theta * sigma_gamma_theta;
  vector[nsite] gamma_pdet = z_p * sigma_gamma_p;

  // linear predictor
  for(i in 1:nsite){
    psi[i] = inv_logit(a_psi + beta * X_Land[i] + gamma_psi[site[i]]); // linear predictor (logit scale) for psi
    for (j in 1:nsamp){
      theta[i, j] = inv_logit(a_theta + gamma_theta[site[i]]); // linear predictor (logit scale) for theta
      for(k in 1:nrep){
        p[i, j, k] = inv_logit(a_p + gamma_pdet[site[i]]); // linear predictor (logit scale) for p
        } // k
      } // j
    } // i
  
  {
    vector[nsamp] tmp_lp;
    matrix[n_possible, nsamp] tmp_poss;
    vector[n_possible + 1] sum_poss;
    
    for (i in 1:nsite) {
      if (known_present[i]) {
        for (j in 1:nsamp) {
           if (known_available[i, j]) {
             // present in site and available for water sample
             tmp_lp[j] = log(theta[i, j]) + bernoulli_lpmf(y[i, j, ] | p[i, j, ]);
          
             } else {
               // present, possibly unavailable for water sample
               tmp_lp[j] = log_sum_exp(
                 log(theta[i, j]) + bernoulli_lpmf(y[i, j, ] | p[i, j, ]), 
                 log1m(theta[i, j])
                 );
               }
        } // j( 1 )
        log_lik[i] = log(psi[i]) + sum(tmp_lp);
      } else {
        // could be present or absent (was never detected)
        // and there are 2^ntime possible combinations
        // of alpha_{i, j} that are relevant if z_i = 1
        for (jj in 1:n_possible) {
          for (j in 1:nsamp) {
            if (alpha_potential[jj, j] == 0) {
              // not available
              tmp_poss[jj, j] = log1m(theta[i, j]);
            } else {
              // available but not detected
              tmp_poss[jj, j] = log(theta[i , j]) + bernoulli_lpmf(y[i, j, ] | p[i, j, ]);
            }
          }
          sum_poss[jj] = log(psi[i]) + sum(tmp_poss[jj, ]);
        } // j( 2 )
        sum_poss[n_possible + 1] = log1m(psi[i]);
        log_lik[i] = log_sum_exp(sum_poss);
      }
    } // i
  }
}

model {
  // priors
  target += normal_lpdf(a_psi | 0, 2);
  target += normal_lpdf(a_theta | 0, 2);
  target += normal_lpdf(a_p | 0, 2);
  target += normal_lpdf(beta | 0, 2);
  target += normal_lpdf(sigma_gamma_psi | 0, 1);
  target += normal_lpdf(sigma_gamma_theta | 0, 1);
  target += normal_lpdf(sigma_gamma_p | 0, 1);
  target += normal_lpdf(z_psi | 0, 1);
  target += normal_lpdf(z_theta | 0, 1);
  target += normal_lpdf(z_p | 0, 1);
  
  // add log-likelihood
  target += sum(log_lik);
}
```

```{r stan_code_2}
# potential combinations of alpha that can lead to all-zero capture history
alpha_potential <- expand.grid(rep(list(c(0, 1)), nsamp))

stan_d <- list(nsite = nsite, 
               nsamp = nsamp, 
               nrep = nrep, 
               X_Land = X_land,
               site = seq(1, nsite, 1),
               y = fake_data, 
               n_possible = 2 ^ nsamp, 
               alpha_potential = alpha_potential)
```

### Fit model
```{r fit_mod1_2}
fit_mod1 <- sampling(
  object = mocc,
  data = stan_d,
  chains = 4,
  iter = 2000,
  cores = 4,
  thin = 1
  )
```

### Print posterior summary
```{r print_mod1_2}
print(fit_mod1, 
       pars = c("a_psi", "a_theta", "a_p", "beta"), 
       digits_summary = 3)
```

$(0.996/0.5) ^ 2 = 4.0$
$30 \times 4.0 = 120$
Need about 120 sites.

```{r plotting_params_2, message=FALSE, warning=FALSE}
#first extract posteriors
posteriors_fit <- rstan::extract(fit_mod1)

#plot
qplot(x = posteriors_fit$psi[ ,1], geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = plogis(a_psi[sel]), color = 'red', size = 2) +
  xlab(expression(psi))

qplot(x = posteriors_fit$theta[ ,1 ,1], geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = plogis(a_theta[sel]), color = 'red', size = 2) +
  xlab(expression(theta))

qplot(x = posteriors_fit$p[ , 1, 1 ,1], geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = plogis(a_p[sel]), color = 'red', size = 2) +
  xlab(expression(p))

qplot(x = posteriors_fit$beta, geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = beta_psi, color = 'red', size = 2) +
  geom_vline(xintercept = 0, color = "blue", linetype = "dashed", size = 2) +
  xlab(expression(Beta))
```


## 200 sites
Increase number of sites from $15 \times 2 = 30$ to $100 \times 2 = 200$

```{r simulation_multilevel_occ_3, echo=TRUE}
nag <- 100 # number of ag sites in study
nurban <- 100 # number of urban sites in study
nsite <- nag + nurban # number of sites in study
nsamp <- 5 # number of replicate water samples per site
nrep <- 4 # number of replicate qPCR samples per water sample (per site and date)
nsim <- 1e3 # number of simulated draws from joint prior predictive distribution
```

```{r n_sites_3}
nsite
```

```{r n_water_samples_3}
nsite * nsamp
```

```{r n_qpcr_runs_3}
nsite * nsamp * nrep
```

```{r containers_multilevel_occupancy_3, include=FALSE}
# make an array placeholder for siumation, s, of the latent occupancy state, z, for each site, i
z_i <- array(NA, dim = c(nsite, nsim))

# make an array placeholder for latent availability state, a, for water rep, j, in site i
a_ij <- array(NA, dim = c(nsite, nsamp, nsim))

# make an array placeholder for simulation, s, of oserved detections, y, for each pcr rep, k, in water sample, j, and site i
y_ijk <- array(NA, dim = c(nsite, nsamp, nrep, nsim))

# make an array placeholder for simulation, s, of the paramter psi or P( site occupied )
psi_i <- array(NA, dim = c(nsite, nsim))

# make an array placeholder for simulation, s, of the parameter theta or P( available in water sample | site occupied )
theta_ij <- array(NA, dim = c(nsite, nsamp, nsim))

# make an array placeholder for simulation, s, of the paramter p or P( detect in PCR rep | available in water sample )
p_ijk <- array(NA, dim = c(nsite, nsamp, nrep, nsim))

```

### Simulate draws
```{r sim_multilevel_occupancy_3, eval=TRUE, include=TRUE}
# Run the prior predictive simulation through likelihood
# Dummy variable for land use
X_land <- c(rep(0, nag), rep(1, nurban))
# Simulate varying effects
gamma_psi <- array(NA, dim = c(nsite, nsim))
gamma_theta <- array(NA, dim = c(nsite, nsim))
gamma_p <- array(NA, dim = c(nsite, nsim))

for (i in 1:nsite){
  gamma_psi[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_psi)
  gamma_theta[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_theta)
  gamma_p[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_p)
}

for(i in 1:nsite){
    psi_i[i, ] <- plogis(a_psi + beta_psi * X_land[i] + gamma_psi[i, ]) # back-transform
    z_i[i, ] <- rbinom(nsim, 1, psi_i[i, ])
  
  for (j in 1:nsamp) {
    theta_ij[i, j, ] <- plogis(a_theta + gamma_theta[i, ]) 
    a_ij[i, j, ] <- rbinom(nsim, 1, z_i[i, ] * theta_ij[i, j, ])
   
    for (k in 1:nrep) {
      p_ijk[i, j, k, ] <- plogis(a_p + gamma_p[i, ])
      y_ijk[i, j, k, ] <- rbinom(nsim, 1, a_ij[i, j, ] * p_ijk[i, j, k, ])
      }
    }
  }
```

### Pick draws at random to analyze
```{r sample_simulation_3}
sel <- sample(1:1000, 1, replace = FALSE)
fake_data <- y_ijk[, , , sel] # draw the fake dataset from 1000 simulations
data.frame(
  a_psi = a_psi[sel],
  beta_psi = beta_psi,
  sigma_gamma_psi = sigma_gamma_psi[[sel]],
  a_theta = a_theta[sel],
  sigma_gamma_theta = sigma_gamma_theta[[sel]],
  a_p = a_p[sel],
  sigma_gamma_p = sigma_gamma_p[[sel]]
) %>% t()
```

```{r stan_code_3}
# potential combinations of alpha that can lead to all-zero capture history
alpha_potential <- expand.grid(rep(list(c(0, 1)), nsamp))

stan_d <- list(nsite = nsite, 
               nsamp = nsamp, 
               nrep = nrep, 
               X_Land = X_land,
               site = seq(1, nsite, 1),
               y = fake_data, 
               n_possible = 2 ^ nsamp, 
               alpha_potential = alpha_potential)
```

### Fit Stan model
```{r fit_mod2_1}
fit_mod2 <- sampling(
  object = mocc,
  data = stan_d,
  chains = 4,
  iter = 2000,
  cores = 4,
  thin = 1
  )
```

### Print posterior summary
```{r print_mod2_2}
print(fit_mod2, 
      pars = c("a_psi", "a_theta", "a_p", "beta"), 
      digits_summary = 3)
```

```{r plotting_params_3, message=FALSE, warning=FALSE}
#first extract posteriors
posteriors_fit_2 <- rstan::extract(fit_mod2)

#plot
qplot(x = posteriors_fit_2$psi[ ,1], geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = plogis(a_psi[sel]), color = 'red', size = 2) +
  xlab(expression(psi))

qplot(x = posteriors_fit_2$theta[ ,1 ,1], geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = plogis(a_theta[sel]), color = 'red', size = 2) +
  xlab(expression(theta))

qplot(x = posteriors_fit_2$p[ , 1, 1 ,1], geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = plogis(a_p[sel]), color = 'red', size = 2) +
  xlab(expression(p))

qplot(x = posteriors_fit_2$beta, geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = beta_psi, color = 'red', size = 2) +
  geom_vline(xintercept = 0, color = "blue", linetype = "dashed", size = 2) +
  xlab(expression(Beta))
```


## Same number of sites, fewer replicates
Same number of sites at $100 \times 2 = 200$, but reduce number of water samples and pcr replicates.

```{r simulation_multilevel_occ_4, echo=TRUE}
nag <- 100 # number of ag sites in study
nurban <- 100 # number of urban sites in study
nsite <- nag + nurban # number of sites in study
nsamp <- 2 # number of replicate water samples per site
nrep <- 2 # number of replicate qPCR samples per water sample (per site and date)
nsim <- 1e3 # number of simulated draws from joint prior predictive distribution
```

```{r n_sites_4}
nsite
```

```{r n_water_samples_4}
nsite * nsamp
```

```{r n_qpcr_runs_4}
nsite * nsamp * nrep
```

```{r containers_multilevel_occupancy_4, include=FALSE}
# make an array placeholder for siumation, s, of the latent occupancy state, z, for each site, i
z_i <- array(NA, dim = c(nsite, nsim))

# make an array placeholder for latent availability state, a, for water rep, j, in site i
a_ij <- array(NA, dim = c(nsite, nsamp, nsim))

# make an array placeholder for simulation, s, of oserved detections, y, for each pcr rep, k, in water sample, j, and site i
y_ijk <- array(NA, dim = c(nsite, nsamp, nrep, nsim))

# make an array placeholder for simulation, s, of the paramter psi or P( site occupied )
psi_i <- array(NA, dim = c(nsite, nsim))

# make an array placeholder for simulation, s, of the parameter theta or P( available in water sample | site occupied )
theta_ij <- array(NA, dim = c(nsite, nsamp, nsim))

# make an array placeholder for simulation, s, of the paramter p or P( detect in PCR rep | available in water sample )
p_ijk <- array(NA, dim = c(nsite, nsamp, nrep, nsim))

```

### Simulate draws
```{r sim_multilevel_occupancy_4, eval=TRUE, include=TRUE}
# Run the prior predictive simulation through likelihood
# Dummy variable for land use
X_land <- c(rep(0, nag), rep(1, nurban))
# Simulate varying effects
gamma_psi <- array(NA, dim = c(nsite, nsim))
gamma_theta <- array(NA, dim = c(nsite, nsim))
gamma_p <- array(NA, dim = c(nsite, nsim))

for (i in 1:nsite){
  gamma_psi[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_psi)
  gamma_theta[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_theta)
  gamma_p[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_p)
}

for(i in 1:nsite){
    psi_i[i, ] <- plogis(a_psi + beta_psi * X_land[i] + gamma_psi[i, ]) # back-transform
    z_i[i, ] <- rbinom(nsim, 1, psi_i[i, ])
  
  for (j in 1:nsamp) {
    theta_ij[i, j, ] <- plogis( a_theta + gamma_theta[i, ]) 
    a_ij[i, j, ] <- rbinom( nsim, 1, z_i[i, ] * theta_ij[i, j, ])
   
    for (k in 1:nrep) {
      p_ijk[i, j, k, ] <- plogis( a_p + gamma_p[i, ])
      y_ijk[i, j, k, ] <- rbinom( nsim, 1, a_ij[ i, j, ] * p_ijk[ i, j, k, ])
      }
    }
  }
```

### Pick draws at random to analyze
```{r sample_simulation_4}
sel <- sample(1:1000, 1, replace = FALSE)
fake_data <- y_ijk[, , , sel] # draw the fake dataset from 1000 simulations
data.frame(
  a_psi = a_psi[sel],
  beta_psi = beta_psi,
  sigma_gamma_psi = sigma_gamma_psi[[sel]],
  a_theta = a_theta[sel],
  sigma_gamma_theta = sigma_gamma_theta[[sel]],
  a_p = a_p[sel],
  sigma_gamma_p = sigma_gamma_p[[sel]]
) %>% t()
```

```{r stan_code_4}
# potential combinations of alpha that can lead to all-zero capture history
alpha_potential <- expand.grid(rep(list(c(0, 1)), nsamp))

stan_d <- list(nsite = nsite, 
               nsamp = nsamp, 
               nrep = nrep, 
               X_Land = X_land,
               site = seq(1, nsite, 1),
               y = fake_data, 
               n_possible = 2 ^ nsamp, 
               alpha_potential = alpha_potential)
```

### Fit Stan model
```{r fit_mod1_4}
fit_mod3 <- sampling(
  object = mocc,
  data = stan_d,
  chains = 4,
  iter = 2000,
  cores = 4,
  thin = 1
  )
```

### Print posterior summary
```{r print_mod1_4}
print(fit_mod3, 
      pars = c("a_psi", "a_theta", "a_p", "beta"), 
      digits_summary = 3)
```

$(0.55/0.5) ^ 2 = 1.21$
$200 \times 1.7 = 242$

```{r plotting_params_4, message=FALSE, warning=FALSE}
#first extract posteriors
posteriors_fit_3 <- rstan::extract(fit_mod3)

#plot
qplot(x = posteriors_fit_3$psi[ ,1 ], geom = 'histogram', binwidth = 0.01 ) +
  geom_vline(xintercept = plogis(a_psi[sel]), color = 'red', size = 2) +
  xlab(expression(psi))

qplot(x = posteriors_fit_3$theta[ ,1 ,1], geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = plogis(a_theta[sel]), color = 'red', size = 2) +
  xlab(expression(theta))

qplot(x = posteriors_fit_3$p[ , 1, 1 ,1], geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = plogis(a_p[sel]), color = 'red', size = 2) +
  xlab(expression(p))

qplot(x = posteriors_fit_3$beta, geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = beta_psi, color = 'red', size = 2) +
  geom_vline(xintercept = 0, color = "blue", linetype = "dashed", size = 2) +
  xlab(expression(Beta))
```


## Same number of sites, lower prior $\theta$
Same number of sites at $100 \times 2 = 200$, but change prior for probability of capturing DNA in water sample, conditional on occupancy.

```{r simulation_multilevel_occ_5, echo=TRUE}
nag <- 100 # number of ag sites in study
nurban <- 100 # number of urban sites in study
nsite <- nag + nurban # number of sites in study
nsamp <- 5 # number of replicate water samples per site
nrep <- 4 # number of replicate qPCR samples per water sample (per site and date)
nsim <- 1e3 # number of simulated draws from joint prior predictive distribution
```

```{r n_sites_5}
nsite
```

```{r n_water_samples_5}
nsite * nsamp
```

```{r n_qpcr_runs_5}
nsite * nsamp * nrep
```

```{r containers_multilevel_occupancy_5, include=FALSE}
# make an array placeholder for siumation, s, of the latent occupancy state, z, for each site, i
z_i <- array(NA, dim = c(nsite, nsim))

# make an array placeholder for latent availability state, a, for water rep, j, in site i
a_ij <- array(NA, dim = c(nsite, nsamp, nsim))

# make an array placeholder for simulation, s, of oserved detections, y, for each pcr rep, k, in water sample, j, and site i
y_ijk <- array(NA, dim = c(nsite, nsamp, nrep, nsim))

# make an array placeholder for simulation, s, of the paramter psi or P( site occupied )
psi_i <- array(NA, dim = c(nsite, nsim))

# make an array placeholder for simulation, s, of the parameter theta or P( available in water sample | site occupied )
theta_ij <- array(NA, dim = c(nsite, nsamp, nsim))

# make an array placeholder for simulation, s, of the paramter p or P( detect in PCR rep | available in water sample )
p_ijk <- array(NA, dim = c(nsite, nsamp, nrep, nsim))

```

### Intercept $\theta$ prior
The old prior.
```{r prior_theta_logodds_5, fig.align='center', fig.width=6, fig.height=4}
# prior for log-odds-scale intercept parameter for psi
loc_a_theta = 1.5
scale_a_theta = 0.25
a_theta <- rnorm(nsim, loc_a_theta, scale_a_theta)
```


```{r prior_theta_prob_5, echo=FALSE, fig.align='center', fig.height=4, fig.width=4}
# plot it
ggplot(tibble(x = plogis(seq(- 10, 10, 0.01)), y = dnorm(seq(- 10, 10, 0.01), loc_a_theta, scale_a_theta)), 
        aes(x = x, y = y)) + 
  geom_line() + 
  ylab("density") + xlab(expression(paste(logit ^ -1, (alpha[theta])))) +
  scale_x_continuous(limits = c(0, 1 ))
```

The new prior: reduced probability of capturing in water sample, conditional on occupancy.
```{r prior_theta_logodds_5b, fig.align='center', fig.width=6, fig.height=4}
# prior for log-odds-scale intercept parameter for psi
loc_a_theta = -1
scale_a_theta = 0.5
a_theta <- rnorm(nsim, loc_a_theta, scale_a_theta)
```


```{r prior_theta_prob_5b, echo=FALSE, fig.align='center', fig.height=4, fig.width=4}
# plot it
ggplot(tibble(x = plogis(seq(- 10, 10, 0.01)), y = dnorm(seq(- 10, 10, 0.01), loc_a_theta, scale_a_theta)), 
        aes(x = x, y = y)) + 
  geom_line() + 
  ylab("density") + xlab(expression(paste(logit ^ -1, (alpha[theta])))) +
  scale_x_continuous(limits = c(0, 1))
```


## Simulate draws
```{r sim_multilevel_occupancy_5, eval=TRUE, include=TRUE}
# Run the prior predictive simulation through likelihood
# Dummy variable for land use
X_land <- c(rep(0, nag), rep(1, nurban))
# Simulate varying effects
gamma_psi <- array(NA, dim = c(nsite, nsim))
gamma_theta <- array(NA, dim = c(nsite, nsim))
gamma_p <- array(NA, dim = c(nsite, nsim))

for (i in 1:nsite){
  gamma_psi[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_psi)
  gamma_theta[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_theta)
  gamma_p[i, ] <- rnorm(nsim, mean = 0, sd = sigma_gamma_p)
}

for(i in 1:nsite){
    psi_i[i, ] <- plogis(a_psi + beta_psi * X_land[i] + gamma_psi[i, ]) # back-transform
    z_i[i, ] <- rbinom(nsim, 1, psi_i[i, ])
  
  for (j in 1:nsamp) {
    theta_ij[i, j, ] <- plogis( a_theta + gamma_theta[i, ]) 
    a_ij[i, j, ] <- rbinom(nsim, 1, z_i[i, ] * theta_ij[i, j, ])
   
    for (k in 1:nrep) {
      p_ijk[i, j, k, ] <- plogis(a_p + gamma_p[i, ])
      y_ijk[i, j, k, ] <- rbinom(nsim, 1, a_ij[ i, j, ] * p_ijk[ i, j, k, ])
      }
    }
  }
```

### Pick draws at random to analyze
```{r sample_simulation_5}
sel <- sample(1:1000, 1, replace = FALSE)
fake_data <- y_ijk[, , , sel] # draw the fake dataset from 1000 simulations
data.frame(
  a_psi = a_psi[sel],
  beta_psi = beta_psi,
  sigma_gamma_psi = sigma_gamma_psi[[sel]],
  a_theta = a_theta[sel],
  sigma_gamma_theta = sigma_gamma_theta[[sel]],
  a_p = a_p[sel],
  sigma_gamma_p = sigma_gamma_p[[sel]]
) %>% t()
```

```{r stan_code_5}
# potential combinations of alpha that can lead to all-zero capture history
alpha_potential <- expand.grid(rep(list(c(0, 1)), nsamp))

stan_d <- list(nsite = nsite, 
               nsamp = nsamp, 
               nrep = nrep, 
               X_Land = X_land,
               site = seq(1, nsite, 1),
               y = fake_data, 
               n_possible = 2 ^ nsamp, 
               alpha_potential = alpha_potential)
```

## Fit Stan model
```{r fit_mod1_5}
fit_mod4 <- sampling(
  object = mocc,
  data = stan_d,
  chains = 4,
  iter = 2000,
  cores = 4,
  thin = 1
  )
```

### Print posterior summary
```{r print_mod1_5}
print(fit_mod4, 
      pars = c("a_psi", "a_theta", "a_p", "beta"), 
      digits_summary = 3)
```

$(1.037/0.5)^2 = 4.3$
$200 \times 4.3 = 860$

```{r plotting_params_5, message=FALSE, warning=FALSE}
#first extract posteriors
posteriors_fit_4 <- rstan::extract(fit_mod4)

#plot
qplot(x = posteriors_fit_4$psi[ ,1], geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = plogis(a_psi[sel]), color = 'red', size = 2) +
  xlab(expression(psi))

qplot(x = posteriors_fit_4$theta[ ,1 ,1], geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = plogis(a_theta[sel]), color = 'red', size = 2) +
  xlab(expression(theta))

qplot(x = posteriors_fit_4$p[ , 1, 1 , 1], geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = plogis(a_p[sel]), color = 'red', size = 2) +
  xlab(expression(p))

qplot(x = posteriors_fit_4$beta, geom = 'histogram', binwidth = 0.01) +
  geom_vline(xintercept = beta_psi, color = 'red', size = 2) +
  geom_vline(xintercept = 0, color = "blue", linetype = "dashed", size = 2) +
  xlab(expression(beta))
```

The "winners curse" describes how, when you infer an effect by chance, it tends to be over-estimated. The "winners curse" is a commonly cited phenomenon with relevance to the replication crisis because these types of noisy findings often get published uncritically, because of over-reliance on and misunderstanding of p-values. In all of these cases above, and also in the frequentist mode of inference, we want to look at the standard error of the effect estimate relative to the known true effect (or a hypothetical effect size of interest if looking at estimates from real data and planning future studies). The effect estimates were too noisy in many of these cases above. That is, relative to the known true effect size (1). Standard errors decrease proportional to the square of sample size.